该部分课程提供如下阅读文献，供同学们参考。 

[1] Anaby-Tavor A, Carmeli B, Goldbraich E, et al. Do not have enough data? Deep learning to the rescue![C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(05): 7383-7390.  
[2] De Angeli K, Gao S, Danciu I, et al. Class imbalance in out-of-distribution datasets: Improving the robustness of the TextCNN for the classification of rare cancer types[J]. Journal of biomedical informatics, 2022, 125: 103957.  
[3] Chen J, Yang Z, Yang D. Mixtext: Linguistically-informed interpolation of hidden space for semi-supervised text classification[J]. arXiv preprint arXiv:2004.12239, 2020.  
[4] Feng S Y, Gangal V, Kang D, et al. GenAug: Data Augmentation for Finetuning Text Generators[C]//Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. 2020: 29-42.  
[5] Guo H. Nonlinear mixup: Out-of-manifold data augmentation for text classification[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(04): 4044-4051.   
[6] Gururangan S, Dang T, Card D, et al. Variational Pretraining for Semi-supervised Text Classification[C]//Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019: 5880-5894.  
[7] Karimi A, Rossi L, Prati A. AEDA: An Easier Data Augmentation Technique for Text Classification[C]//Findings of the Association for Computational Linguistics: EMNLP 2021. 2021: 2748-2754.  
[8] Kedzie C, Mckeown K. A Good Sample is Hard to Find: Noise Injection Sampling and Self-Training for Neural Language Generation Models[C]//Proceedings of the 12th International Conference on Natural Language Generation. 2019: 584-593.  
[9] Kim D, Koo J, Kim U M. EnvBERT: Multi-Label Text Classification for Imbalanced, Noisy Environmental News Data[C]//2021 15th International Conference on Ubiquitous Information Management and Communication (IMCOM). IEEE, 2021: 1-8.  
[10] Kumar V, Choudhary A, Cho E. Data Augmentation using Pre-trained Transformer Models[C]//Proceedings of the 2nd Workshop on Life-long Learning for Spoken Language Systems. 2020: 18-26.  
[11] Li Y, Cohn T, Baldwin T. Robust training under linguistic adversity[C]//Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers. 2017: 21-27.  
[12] Liu R, Xu G, Jia C, et al. Data Boost: Text Data Augmentation Through Reinforcement Learning Guided Conditional Generation[C]//Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020: 9031-9041.  
[13] Montella S, Fabre B, Urvoy T, et al. Denoising Pre-Training and Data Augmentation Strategies for Enhanced RDF Verbalization with Transformers[C]//Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+). 2020: 89-99.  
